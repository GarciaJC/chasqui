{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25a400bc-cfc4-4852-bd63-c41e0690fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d22fc7-cc29-4fb9-aafc-4d2e30123cf8",
   "metadata": {},
   "source": [
    "# Sync Operations\n",
    "> Remote synchronization engine for chasqui workflow automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d60fcb4-803b-4275-973d-321e65d2ca90",
   "metadata": {},
   "source": [
    "This module handles all communication between local and remote systems:\n",
    "\n",
    "- Upload jobs from local queue to remote waiting directory\n",
    "- Trigger remote agent to process waiting jobs\n",
    "- Parse remote agent logs and update local database\n",
    "- Download completed results\n",
    "\n",
    "## Key Design Decisions\n",
    "\n",
    "**Manual 2FA Requirement:** All remote operations happen in a single SSH session \n",
    "to minimize authentication overhead.\n",
    "\n",
    "**Lightweight Remote State:** Remote side uses append-only log files rather than \n",
    "a database for simplicity and robustness.\n",
    "\n",
    "**Self-Perpetuating Queue:** Completed PBS jobs trigger the agent to submit \n",
    "waiting jobs, eliminating need for cron.\n",
    "\n",
    "## Workflow\n",
    "```\n",
    "1. Get QUEUED_LOCAL jobs from database\n",
    "2. Upload VASP inputs to remote work directories\n",
    "3. Generate and upload PBS scripts to waiting/\n",
    "4. Trigger agent to submit jobs\n",
    "5. Parse agent log to see what was submitted\n",
    "6. Update local database with submission status\n",
    "7. Check for completed jobs (flags)\n",
    "8. Update database and optionally download results\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4193274-50a0-422c-8a2f-ac80de2e0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional, List, Dict, Any\n",
    "import json\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "from chasqui.database import ChasquiDB\n",
    "from chasqui.ssh import SSHConnection\n",
    "from chasqui.templates import generate_pbs_script_from_job\n",
    "from chasqui.agent import deploy_agent, trigger_agent, parse_agent_log\n",
    "\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed07abc-6016-4da1-a679-db2716e7afdb",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "The sync operation follows this flow:\n",
    "```\n",
    "Local DB → SSH Connection → Remote System\n",
    "   ↓                            ↓\n",
    "QUEUED_LOCAL              waiting/*.sh\n",
    "   ↓                            ↓\n",
    "UPLOADED                  agent.sh (triggered)\n",
    "   ↓                            ↓\n",
    "SUBMITTED ←── agent.log ←── PBS Queue\n",
    "   ↓\n",
    "COMPLETED\n",
    "```\n",
    "\n",
    "The `sync()` function orchestrates all operations in a single SSH session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102364ce-18a5-4155-947d-463c3ab442bf",
   "metadata": {},
   "source": [
    "## Sync Configuration\n",
    "\n",
    "Store sync parameters in a configuration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec207afa-74a5-4b0d-8205-2e6ae4398899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SyncConfig:\n",
    "    \"\"\"\n",
    "    Configuration for sync operations.\n",
    "    \n",
    "    Example:\n",
    "        >>> config = SyncConfig(\n",
    "        ...     remote_host='bebop',\n",
    "        ...     chasqui_remote_dir='$HOME/chasqui_remote',\n",
    "        ...     max_queued=40,\n",
    "        ...     max_running=30\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        remote_host: str = 'bebop',\n",
    "        chasqui_remote_dir: str = '$HOME/chasqui_remote',\n",
    "        max_queued: int = 40,\n",
    "        max_running: int = 30,\n",
    "        auto_deploy_agent: bool = True,\n",
    "        download_results: bool = False\n",
    "    ):\n",
    "        self.remote_host = remote_host\n",
    "        self.chasqui_remote_dir = chasqui_remote_dir\n",
    "        self.max_queued = max_queued\n",
    "        self.max_running = max_running\n",
    "        self.auto_deploy_agent = auto_deploy_agent\n",
    "        self.download_results = download_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe971c-93e5-4923-925e-0b43bcdb3ebb",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Internal functions for sync operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8195ca2c-0ebd-4004-b735-aa9ed986dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _upload_vasp_inputs(\n",
    "    ssh: SSHConnection,\n",
    "    job: Dict[str, Any],\n",
    "    work_dir: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Upload VASP input files to remote work directory.\n",
    "    \n",
    "    Args:\n",
    "        ssh: Active SSH connection\n",
    "        job: Job dictionary from database\n",
    "        work_dir: Remote work directory (expanded path)\n",
    "    \"\"\"\n",
    "    local_path = Path(job['local_path']).expanduser()\n",
    "    \n",
    "    if not local_path.exists():\n",
    "        raise FileNotFoundError(f\"Local job directory not found: {local_path}\")\n",
    "    \n",
    "    # Create remote work directory\n",
    "    ssh.run(f'mkdir -p {work_dir}')\n",
    "    \n",
    "    # Upload VASP input files\n",
    "    for filename in ['POSCAR', 'INCAR', 'KPOINTS', 'POTCAR']:\n",
    "        local_file = local_path / filename\n",
    "        if local_file.exists():\n",
    "            remote_file = f\"{work_dir}/{filename}\"\n",
    "            ssh.upload(str(local_file), remote_file)\n",
    "        # Note: POTCAR might not exist for some test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71b3a7de-5930-449a-af16-32060f751e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _upload_pbs_script(\n",
    "    ssh: SSHConnection,\n",
    "    job: Dict[str, Any],\n",
    "    work_dir: str,\n",
    "    waiting_dir: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate and upload PBS script to waiting directory.\n",
    "    \n",
    "    Args:\n",
    "        ssh: Active SSH connection\n",
    "        job: Job dictionary from database\n",
    "        work_dir: Remote work directory (expanded)\n",
    "        waiting_dir: Remote waiting directory (expanded)\n",
    "        \n",
    "    Returns:\n",
    "        Remote script path\n",
    "    \"\"\"\n",
    "    # Generate PBS script with work_dir\n",
    "    job_with_workdir = job.copy()\n",
    "    if job_with_workdir.get('vasp_config'):\n",
    "        config = json.loads(job_with_workdir['vasp_config'])\n",
    "        config['remote_work_dir'] = work_dir\n",
    "        job_with_workdir['vasp_config'] = json.dumps(config)\n",
    "    else:\n",
    "        job_with_workdir['vasp_config'] = json.dumps({'remote_work_dir': work_dir})\n",
    "    \n",
    "    script = generate_pbs_script_from_job(job_with_workdir)\n",
    "    \n",
    "    # Write to temporary local file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.sh', delete=False) as tmp:\n",
    "        tmp.write(script)\n",
    "        tmp_path = tmp.name\n",
    "    \n",
    "    try:\n",
    "        # Upload to waiting directory\n",
    "        remote_script = f\"{waiting_dir}/{job['job_id']}.sh\"\n",
    "        ssh.upload(tmp_path, remote_script)\n",
    "        return remote_script\n",
    "    finally:\n",
    "        os.unlink(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dac780c-bbeb-4797-938a-0c72191b4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _check_completed_jobs(\n",
    "    ssh: SSHConnection,\n",
    "    completed_dir: str,\n",
    "    jobs: List[Dict[str, Any]]\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Check for completion flags and parse them.\n",
    "    \n",
    "    Args:\n",
    "        ssh: Active SSH connection\n",
    "        completed_dir: Remote completed directory (expanded)\n",
    "        jobs: List of job dictionaries to check\n",
    "        \n",
    "    Returns:\n",
    "        List of completed job updates: [{'job_id': ..., 'status': 'DONE', 'pbs_id': ...}, ...]\n",
    "    \"\"\"\n",
    "    completed = []\n",
    "    \n",
    "    for job in jobs:\n",
    "        job_id = job['job_id']\n",
    "        flag_file = f\"{completed_dir}/{job_id}.flag\"\n",
    "        \n",
    "        if ssh.exists(flag_file):\n",
    "            # Read flag content\n",
    "            flag_content = ssh.run(f'cat {flag_file}')\n",
    "            lines = flag_content.strip().split('\\n')\n",
    "            \n",
    "            if len(lines) >= 1:\n",
    "                status = lines[0].strip()  # DONE or FAIL\n",
    "                pbs_id = lines[1].strip() if len(lines) > 1 else None\n",
    "                \n",
    "                completed.append({\n",
    "                    'job_id': job_id,\n",
    "                    'status': status,\n",
    "                    'pbs_id': pbs_id\n",
    "                })\n",
    "    \n",
    "    return completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ddc414-ef59-47c4-b7e1-643446d92b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sync(\n",
    "    local_db_path: str = \"~/.chasqui/jobs.db\",\n",
    "    remote_host: Optional[str] = None,\n",
    "    dry_run: bool = False\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Synchronize local and remote job queues.\n",
    "    \n",
    "    This is the main orchestration function that:\n",
    "    \n",
    "    1. Uploads queued jobs to remote\n",
    "    \n",
    "    2. Triggers remote agent\n",
    "    \n",
    "    3. Syncs job status back to local DB\n",
    "    \n",
    "    4. Downloads completed results (optional)\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        local_db_path: Path to local SQLite database\n",
    "        \n",
    "        remote_host: SSH connection string (e.g., 'user@hpc.cluster.edu')\n",
    "                     If None, reads from config\n",
    "                     \n",
    "        dry_run: If True, show what would happen without executing\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        Dictionary with sync statistics:\n",
    "        {\n",
    "            'uploaded': 5,\n",
    "            'submitted': 3,\n",
    "            'completed': 2,\n",
    "            'failed': 0,\n",
    "            'timestamp': '2025-10-28T10:30:00Z'\n",
    "        }\n",
    "        \n",
    "    Example:\n",
    "    \n",
    "        >>> result = sync()\n",
    "        >>> print(f\"Uploaded {result['uploaded']} jobs\")\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    # For now, return a placeholder\n",
    "    return {\n",
    "        'uploaded': 0,\n",
    "        'submitted': 0,\n",
    "        'completed': 0,\n",
    "        'failed': 0,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f133d90-44fc-4b32-a473-18d65240d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ sync() skeleton works\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# This cell won't be exported, but runs during nbdev_test\n",
    "\n",
    "# Test that function exists and returns expected structure\n",
    "result = sync(dry_run=True)\n",
    "assert 'uploaded' in result\n",
    "assert 'timestamp' in result\n",
    "print(\"✓ sync() skeleton works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661dae70-82ca-4019-8dd0-cb3889cb7e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
