{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35369b92-970c-4070-9545-b395558819f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec18fac-d363-4a6c-8f2b-2b50c1d63362",
   "metadata": {},
   "source": [
    "# Database Layer\n",
    "> Local job queue database for chasqui workflow automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b9ce9-5677-488c-aba4-ea39f4eb2c32",
   "metadata": {},
   "source": [
    "This module manages the local SQLite database that tracks all jobs through their lifecycle.\n",
    "\n",
    "## Design Principles\n",
    "\n",
    "- Single source of truth: All job state lives here\n",
    "- Immutable history: State transitions are logged, never overwritten\n",
    "- Simple schema: Lightweight, just what we need\n",
    "- Transaction safety: All writes are atomic\n",
    "\n",
    "## Job State Machine\n",
    "```\n",
    "PREPARED → QUEUED_LOCAL → UPLOADED → SUBMITTED → RUNNING → COMPLETED\n",
    "                                                         ↘ FAILED\n",
    "```\n",
    "\n",
    "## Schema\n",
    "\n",
    "**jobs table:**\n",
    "- Tracks individual jobs through their lifecycle\n",
    "- Primary key: `job_id` (UUID)\n",
    "- State field tracks current status\n",
    "- Timestamps for all transitions\n",
    "\n",
    "**sync_log table:**\n",
    "- Audit trail of all sync operations\n",
    "- Helps with debugging and recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b513a357-9609-48d3-89d3-7930eec3c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "from contextlib import contextmanager\n",
    "import json\n",
    "import uuid\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef592a07-64e5-44ad-b89f-6f36c7a3316d",
   "metadata": {},
   "source": [
    "## Database Schema\n",
    "\n",
    "We keep it minimal but extensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f5ddad-bcc8-45cc-b555-e199d5597336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "SCHEMA_SQL = \"\"\"\n",
    "-- Jobs table: tracks all jobs through their lifecycle\n",
    "CREATE TABLE IF NOT EXISTS jobs (\n",
    "    job_id TEXT PRIMARY KEY,\n",
    "    state TEXT NOT NULL CHECK(state IN (\n",
    "        'PREPARED', 'QUEUED_LOCAL', 'UPLOADED', \n",
    "        'SUBMITTED', 'RUNNING', 'COMPLETED', 'FAILED'\n",
    "    )),\n",
    "    \n",
    "    -- Timestamps\n",
    "    created_at TEXT NOT NULL,\n",
    "    queued_at TEXT,\n",
    "    uploaded_at TEXT,\n",
    "    submitted_at TEXT,\n",
    "    completed_at TEXT,\n",
    "    downloaded_at TEXT,  \n",
    "    \n",
    "    -- Local information\n",
    "    local_path TEXT NOT NULL,\n",
    "    vasp_config TEXT,  -- JSON blob with VASP parameters\n",
    "    \n",
    "    -- Remote information\n",
    "    remote_path TEXT,\n",
    "    pbs_id TEXT,  -- PBS job ID (null until submitted)\n",
    "    \n",
    "    -- Sync tracking\n",
    "    last_synced TEXT,\n",
    "    downloaded INTEGER DEFAULT 0  -- Boolean: results downloaded?\n",
    ");\n",
    "\n",
    "-- Index for common queries\n",
    "CREATE INDEX IF NOT EXISTS idx_jobs_state ON jobs(state);\n",
    "CREATE INDEX IF NOT EXISTS idx_jobs_pbs_id ON jobs(pbs_id);\n",
    "\n",
    "-- Sync log: audit trail of all sync operations\n",
    "CREATE TABLE IF NOT EXISTS sync_log (\n",
    "    sync_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    timestamp TEXT NOT NULL,\n",
    "    uploaded INTEGER DEFAULT 0,\n",
    "    submitted INTEGER DEFAULT 0,\n",
    "    completed INTEGER DEFAULT 0,\n",
    "    failed INTEGER DEFAULT 0,\n",
    "    downloaded INTEGER DEFAULT 0,\n",
    "    details TEXT  -- JSON blob with additional info\n",
    ");\n",
    "\n",
    "-- Schema version tracking\n",
    "CREATE TABLE IF NOT EXISTS schema_version (\n",
    "    version INTEGER PRIMARY KEY,\n",
    "    applied_at TEXT NOT NULL\n",
    ");\n",
    "\n",
    "INSERT OR IGNORE INTO schema_version (version, applied_at)\n",
    "VALUES (1, datetime('now'));\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5dec4d-22ad-4a83-a6c4-54d72bed0ac7",
   "metadata": {},
   "source": [
    "## Base class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4430d39-ad44-4e4c-9f48-f946d4f845b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ChasquiDB:\n",
    "    \"\"\"\n",
    "    SQLite database manager for chasqui job tracking.\n",
    "    \n",
    "    Example:\n",
    "        >>> db = ChasquiDB(\"~/.chasqui/jobs.db\")\n",
    "        >>> db.init_db()\n",
    "        >>> job_id = db.create_job(local_path=\"/path/to/job\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"~/.chasqui/jobs.db\"):\n",
    "        \"\"\"\n",
    "        Initialize database connection.\n",
    "        \n",
    "        Args:\n",
    "            db_path: Path to SQLite database file\n",
    "        \"\"\"\n",
    "        self.db_path = Path(db_path).expanduser()\n",
    "        self.db_path.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824492ce-15fc-45fc-97c4-c251a6887519",
   "metadata": {},
   "source": [
    "## Connection Management\n",
    "\n",
    "We use a context manager to ensure database connections are properly handled.\n",
    "This pattern ensures commits happen on success and rollbacks on errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70bc59ff-6f69-4f83-8135-44b51acb6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "@contextmanager\n",
    "def _connect(self: ChasquiDB):\n",
    "    \"\"\"Context manager for database connections.\"\"\"\n",
    "    conn = sqlite3.connect(self.db_path)\n",
    "    conn.row_factory = sqlite3.Row  # Access columns by name\n",
    "    try:\n",
    "        yield conn\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        raise e\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "@patch\n",
    "def init_db(self: ChasquiDB):\n",
    "    \"\"\"Initialize database schema.\"\"\"\n",
    "    with self._connect() as conn:\n",
    "        conn.executescript(SCHEMA_SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a04fc-38bf-4ae3-a19e-9a93537ab241",
   "metadata": {},
   "source": [
    "## Creating Jobs\n",
    "\n",
    "New jobs start in the `PREPARED` state. They contain:\n",
    "- A unique UUID identifier\n",
    "- Path to local VASP inputs\n",
    "- Optional configuration parameters (stored as JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173f340d-6f70-4dde-964f-50da32b15194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def create_job(\n",
    "    self: ChasquiDB,\n",
    "    local_path: str,\n",
    "    vasp_config: Optional[Dict[str, Any]] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create a new job in PREPARED state.\n",
    "    \n",
    "    Args:\n",
    "        local_path: Path to local directory with VASP inputs\n",
    "        vasp_config: Dictionary with VASP parameters (optional)\n",
    "        \n",
    "    Returns:\n",
    "        job_id: UUID for the created job\n",
    "        \n",
    "    Example:\n",
    "        >>> db = ChasquiDB()\n",
    "        >>> job_id = db.create_job(\n",
    "        ...     local_path=\"/scratch/vasp_job_001\",\n",
    "        ...     vasp_config={\"encut\": 500, \"kpoints\": [4,4,4]}\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    job_id = str(uuid.uuid4())\n",
    "    now = datetime.now().isoformat()\n",
    "    \n",
    "    with self._connect() as conn:\n",
    "        conn.execute(\"\"\"\n",
    "            INSERT INTO jobs (job_id, state, created_at, local_path, vasp_config)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            job_id,\n",
    "            'PREPARED',\n",
    "            now,\n",
    "            local_path,\n",
    "            json.dumps(vasp_config) if vasp_config else None\n",
    "        ))\n",
    "    \n",
    "    return job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fbd123-a09d-46ce-840d-418af17908a1",
   "metadata": {},
   "source": [
    "## State Transitions\n",
    "\n",
    "Jobs move through states as they progress. Each transition:\n",
    "- Updates the state field\n",
    "- Records a timestamp\n",
    "- Can update additional fields (like PBS ID)\n",
    "\n",
    "The state machine enforces valid transitions through the CHECK constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "018441af-fbe1-414b-9a3b-f2536c744a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def update_state(\n",
    "    self: ChasquiDB,\n",
    "    job_id: str,\n",
    "    new_state: str,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Update job state and related fields.\n",
    "    \n",
    "    Args:\n",
    "        job_id: Job UUID\n",
    "        new_state: New state value\n",
    "        **kwargs: Additional fields to update (e.g., pbs_id, remote_path)\n",
    "        \n",
    "    Example:\n",
    "        >>> db.update_state(\"abc-123\", \"SUBMITTED\", pbs_id=\"12345678\")\n",
    "    \"\"\"\n",
    "    # Build UPDATE statement dynamically\n",
    "    timestamp_field = {\n",
    "        'QUEUED_LOCAL': 'queued_at',\n",
    "        'UPLOADED': 'uploaded_at',\n",
    "        'SUBMITTED': 'submitted_at',\n",
    "        'COMPLETED': 'completed_at',\n",
    "        'FAILED': 'completed_at'\n",
    "    }.get(new_state)\n",
    "    \n",
    "    updates = {'state': new_state}\n",
    "    if timestamp_field:\n",
    "        updates[timestamp_field] = datetime.now().isoformat()\n",
    "    updates.update(kwargs)\n",
    "    \n",
    "    # Build SQL\n",
    "    set_clause = ', '.join(f\"{k} = ?\" for k in updates.keys())\n",
    "    values = list(updates.values()) + [job_id]\n",
    "    \n",
    "    with self._connect() as conn:\n",
    "        conn.execute(\n",
    "            f\"UPDATE jobs SET {set_clause} WHERE job_id = ?\",\n",
    "            values\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4b107-c639-44cb-86af-43892e4f785b",
   "metadata": {},
   "source": [
    "## Querying Jobs\n",
    "\n",
    "Common query patterns for retrieving job information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d14b6d3-5d1c-452b-842d-446339ae9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def get_job(self: ChasquiDB, job_id: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Get job by ID.\"\"\"\n",
    "    with self._connect() as conn:\n",
    "        row = conn.execute(\n",
    "            \"SELECT * FROM jobs WHERE job_id = ?\",\n",
    "            (job_id,)\n",
    "        ).fetchone()\n",
    "        return dict(row) if row else None\n",
    "\n",
    "@patch\n",
    "def get_jobs_by_state(self: ChasquiDB, state: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Get all jobs in a given state.\"\"\"\n",
    "    with self._connect() as conn:\n",
    "        rows = conn.execute(\n",
    "            \"SELECT * FROM jobs WHERE state = ?\",\n",
    "            (state,)\n",
    "        ).fetchall()\n",
    "        return [dict(row) for row in rows]\n",
    "\n",
    "@patch\n",
    "def get_all_jobs(self: ChasquiDB) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Get all jobs.\"\"\"\n",
    "    with self._connect() as conn:\n",
    "        rows = conn.execute(\"SELECT * FROM jobs ORDER BY created_at\").fetchall()\n",
    "        return [dict(row) for row in rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317da01-26ca-4c7c-a7ee-d82fb6fb79f8",
   "metadata": {},
   "source": [
    "## Sync Audit Log\n",
    "\n",
    "Track all synchronization operations for debugging and monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52961611-ec8c-41db-a522-2d8e4189559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def log_sync(\n",
    "    self: ChasquiDB,\n",
    "    uploaded: int = 0,\n",
    "    submitted: int = 0,\n",
    "    completed: int = 0,\n",
    "    failed: int = 0,\n",
    "    downloaded: int = 0,  # ADD THIS PARAMETER\n",
    "    details: Optional[Dict[str, Any]] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Record a sync operation.\n",
    "    \n",
    "    Args:\n",
    "        uploaded: Number of jobs uploaded\n",
    "        submitted: Number of jobs submitted to PBS\n",
    "        completed: Number of jobs completed\n",
    "        failed: Number of jobs failed\n",
    "        downloaded: Number of files downloaded  # ADD THIS LINE\n",
    "        details: Additional information (optional)\n",
    "    \"\"\"\n",
    "    now = datetime.now().isoformat()\n",
    "    \n",
    "    with self._connect() as conn:\n",
    "        conn.execute(\"\"\"\n",
    "            INSERT INTO sync_log \n",
    "            (timestamp, uploaded, submitted, completed, failed, downloaded, details)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            now,\n",
    "            uploaded,\n",
    "            submitted,\n",
    "            completed,\n",
    "            failed,\n",
    "            downloaded,  # ADD THIS VALUE\n",
    "            json.dumps(details) if details else None\n",
    "        ))\n",
    "\n",
    "@patch\n",
    "def get_last_sync(self: ChasquiDB) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Get the most recent sync operation.\"\"\"\n",
    "    with self._connect() as conn:\n",
    "        row = conn.execute(\n",
    "            \"SELECT * FROM sync_log ORDER BY sync_id DESC LIMIT 1\"\n",
    "        ).fetchone()\n",
    "        return dict(row) if row else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e0a14c-8cb3-4e71-9d99-a9cc05ba9ccb",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Let's verify the database works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110f93d6-9ffa-4f82-ba80-c33c98ea7dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Database initialized\n",
      "✓ Created job: bb8dd229-bf22-459e-8945-bbe08ea0137b\n",
      "✓ Job created in PREPARED state\n",
      "✓ State transition works\n",
      "✓ Query by state works\n",
      "✓ Sync logging works\n",
      "\n",
      "✅ All tests passed!\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create temporary database for testing\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix='.db') as tmp:\n",
    "    test_db_path = tmp.name\n",
    "\n",
    "try:\n",
    "    # Initialize\n",
    "    db = ChasquiDB(test_db_path)\n",
    "    db.init_db()\n",
    "    print(\"✓ Database initialized\")\n",
    "    \n",
    "    # Create job\n",
    "    job_id = db.create_job(\n",
    "        local_path=\"/test/job\",\n",
    "        vasp_config={\"encut\": 500}\n",
    "    )\n",
    "    assert job_id is not None\n",
    "    print(f\"✓ Created job: {job_id}\")\n",
    "    \n",
    "    # Verify initial state\n",
    "    job = db.get_job(job_id)\n",
    "    assert job['state'] == 'PREPARED'\n",
    "    assert job['local_path'] == '/test/job'\n",
    "    print(\"✓ Job created in PREPARED state\")\n",
    "    \n",
    "    # Update state\n",
    "    db.update_state(job_id, 'QUEUED_LOCAL')\n",
    "    job = db.get_job(job_id)\n",
    "    assert job['state'] == 'QUEUED_LOCAL'\n",
    "    assert job['queued_at'] is not None\n",
    "    print(\"✓ State transition works\")\n",
    "    \n",
    "    # Query by state\n",
    "    queued = db.get_jobs_by_state('QUEUED_LOCAL')\n",
    "    assert len(queued) == 1\n",
    "    assert queued[0]['job_id'] == job_id\n",
    "    print(\"✓ Query by state works\")\n",
    "    \n",
    "    # Log sync\n",
    "    db.log_sync(uploaded=1, submitted=0)\n",
    "    last_sync = db.get_last_sync()\n",
    "    assert last_sync['uploaded'] == 1\n",
    "    print(\"✓ Sync logging works\")\n",
    "    \n",
    "    print(\"\\n✅ All tests passed!\")\n",
    "    \n",
    "finally:\n",
    "    # Cleanup\n",
    "    os.unlink(test_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e0b32-a768-4a6c-964e-302d7313f8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
