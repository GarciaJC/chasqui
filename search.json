[
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "database.html",
    "href": "database.html",
    "title": "Database Layer",
    "section": "",
    "text": "This module manages the local SQLite database that tracks all jobs through their lifecycle.",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#design-principles",
    "href": "database.html#design-principles",
    "title": "Database Layer",
    "section": "Design Principles",
    "text": "Design Principles\n\nSingle source of truth: All job state lives here\nImmutable history: State transitions are logged, never overwritten\nSimple schema: Lightweight, just what we need\nTransaction safety: All writes are atomic",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#job-state-machine",
    "href": "database.html#job-state-machine",
    "title": "Database Layer",
    "section": "Job State Machine",
    "text": "Job State Machine\nPREPARED → QUEUED_LOCAL → UPLOADED → SUBMITTED → RUNNING → COMPLETED\n                                                         ↘ FAILED",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#schema",
    "href": "database.html#schema",
    "title": "Database Layer",
    "section": "Schema",
    "text": "Schema\njobs table: - Tracks individual jobs through their lifecycle - Primary key: job_id (UUID) - State field tracks current status - Timestamps for all transitions\nsync_log table: - Audit trail of all sync operations - Helps with debugging and recovery",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#database-schema",
    "href": "database.html#database-schema",
    "title": "Database Layer",
    "section": "Database Schema",
    "text": "Database Schema\nWe keep it minimal but extensible.",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#base-class-definition",
    "href": "database.html#base-class-definition",
    "title": "Database Layer",
    "section": "Base class definition",
    "text": "Base class definition\n\nsource\n\nChasquiDB\n\n ChasquiDB (db_path:str='~/.chasqui/jobs.db')\n\n*SQLite database manager for chasqui job tracking.\nExample: &gt;&gt;&gt; db = ChasquiDB(“~/.chasqui/jobs.db”) &gt;&gt;&gt; db.init_db() &gt;&gt;&gt; job_id = db.create_job(local_path=“/path/to/job”)*",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#connection-management",
    "href": "database.html#connection-management",
    "title": "Database Layer",
    "section": "Connection Management",
    "text": "Connection Management\nWe use a context manager to ensure database connections are properly handled. This pattern ensures commits happen on success and rollbacks on errors.\n\nsource\n\nChasquiDB.init_db\n\n ChasquiDB.init_db ()\n\nInitialize database schema.",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#creating-jobs",
    "href": "database.html#creating-jobs",
    "title": "Database Layer",
    "section": "Creating Jobs",
    "text": "Creating Jobs\nNew jobs start in the PREPARED state. They contain: - A unique UUID identifier - Path to local VASP inputs - Optional configuration parameters (stored as JSON)\n\nsource\n\nChasquiDB.create_job\n\n ChasquiDB.create_job (local_path:str,\n                       vasp_config:Optional[Dict[str,Any]]=None)\n\n*Create a new job in PREPARED state.\nArgs: local_path: Path to local directory with VASP inputs vasp_config: Dictionary with VASP parameters (optional)\nReturns: job_id: UUID for the created job\nExample: &gt;&gt;&gt; db = ChasquiDB() &gt;&gt;&gt; job_id = db.create_job( … local_path=“/scratch/vasp_job_001”, … vasp_config={“encut”: 500, “kpoints”: [4,4,4]} … )*",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#state-transitions",
    "href": "database.html#state-transitions",
    "title": "Database Layer",
    "section": "State Transitions",
    "text": "State Transitions\nJobs move through states as they progress. Each transition: - Updates the state field - Records a timestamp - Can update additional fields (like PBS ID)\nThe state machine enforces valid transitions through the CHECK constraint.\n\nsource\n\nChasquiDB.update_state\n\n ChasquiDB.update_state (job_id:str, new_state:str, **kwargs)\n\n*Update job state and related fields.\nArgs: job_id: Job UUID new_state: New state value **kwargs: Additional fields to update (e.g., pbs_id, remote_path)\nExample: &gt;&gt;&gt; db.update_state(“abc-123”, “SUBMITTED”, pbs_id=“12345678”)*",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#querying-jobs",
    "href": "database.html#querying-jobs",
    "title": "Database Layer",
    "section": "Querying Jobs",
    "text": "Querying Jobs\nCommon query patterns for retrieving job information.\n\nsource\n\nChasquiDB.get_all_jobs\n\n ChasquiDB.get_all_jobs ()\n\nGet all jobs.\n\nsource\n\n\nChasquiDB.get_jobs_by_state\n\n ChasquiDB.get_jobs_by_state (state:str)\n\nGet all jobs in a given state.\n\nsource\n\n\nChasquiDB.get_job\n\n ChasquiDB.get_job (job_id:str)\n\nGet job by ID.",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#sync-audit-log",
    "href": "database.html#sync-audit-log",
    "title": "Database Layer",
    "section": "Sync Audit Log",
    "text": "Sync Audit Log\nTrack all synchronization operations for debugging and monitoring.\n\nsource\n\nChasquiDB.get_last_sync\n\n ChasquiDB.get_last_sync ()\n\nGet the most recent sync operation.\n\nsource\n\n\nChasquiDB.log_sync\n\n ChasquiDB.log_sync (uploaded:int=0, submitted:int=0, completed:int=0,\n                     failed:int=0, details:Optional[Dict[str,Any]]=None)\n\n*Record a sync operation.\nArgs: uploaded: Number of jobs uploaded submitted: Number of jobs submitted to PBS completed: Number of jobs completed failed: Number of jobs failed details: Additional information (optional)*",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "database.html#tests",
    "href": "database.html#tests",
    "title": "Database Layer",
    "section": "Tests",
    "text": "Tests\nLet’s verify the database works correctly.",
    "crumbs": [
      "Database Layer"
    ]
  },
  {
    "objectID": "templates.html",
    "href": "templates.html",
    "title": "PBS Job Templates",
    "section": "",
    "text": "This module creates PBS scripts that: - Execute VASP calculations with proper environment setup - Handle job completion (success/failure) - Write completion flags for status tracking - Trigger the remote agent to submit waiting jobs - Log execution details",
    "crumbs": [
      "PBS Job Templates"
    ]
  },
  {
    "objectID": "templates.html#template-structure",
    "href": "templates.html#template-structure",
    "title": "PBS Job Templates",
    "section": "Template Structure",
    "text": "Template Structure\nEach generated PBS script includes:\n\nPBS Directives - Resource allocation (#PBS -l, -A, etc.)\nEnvironment Setup - Module loads, ulimit, OMP settings\nVASP Execution - MPI run with proper parameters\nCompletion Handler - Always runs, even on failure\nAgent Trigger - Starts next job submission cycle",
    "crumbs": [
      "PBS Job Templates"
    ]
  },
  {
    "objectID": "templates.html#integration-with-workflow",
    "href": "templates.html#integration-with-workflow",
    "title": "PBS Job Templates",
    "section": "Integration with Workflow",
    "text": "Integration with Workflow\nJob Script Template\n       ↓\n   PBS Queue\n       ↓\n  VASP Runs\n       ↓\nCompletion Handler → Writes flag → Triggers agent.sh\n                                          ↓\n                                   Submits next jobs",
    "crumbs": [
      "PBS Job Templates"
    ]
  },
  {
    "objectID": "templates.html#pbs-script-template",
    "href": "templates.html#pbs-script-template",
    "title": "PBS Job Templates",
    "section": "PBS Script Template",
    "text": "PBS Script Template\nBased on regular script with enhancements for workflow automation.\n\nsource\n\ngenerate_pbs_script\n\n generate_pbs_script (job_id:str, work_dir:str,\n                      job_name:Optional[str]=None, cores:int=1,\n                      walltime:str='48:00:00', project:str='AARC1',\n                      vasp_version:str='vasp_gam',\n                      chasqui_remote_dir:str='~/chasqui_remote',\n                      output_path:Optional[str]=None)\n\n*Generate PBS submission script for VASP job.\nArgs: job_id: Unique job identifier (UUID from database) work_dir: Remote directory where VASP will run (contains POSCAR, INCAR, etc.) job_name: Human-readable job name (default: job_id) cores: Number of compute nodes to request (default: 1) walltime: Maximum runtime in HH:MM:SS format (default: “48:00:00”) project: PBS account/project code (default: “AARC1”) vasp_version: VASP executable name (default: “vasp_gam”) chasqui_remote_dir: Remote chasqui directory (default: “~/chasqui_remote”) output_path: If provided, write script to this file\nReturns: PBS script content as string\nExample: &gt;&gt;&gt; script = generate_pbs_script( … job_id=“abc-123-def”, … work_dir=“~/scratch/vasp_jobs/abc-123-def”, … job_name=“Au_bulk_relax”, … cores=2, … walltime=“24:00:00”, … project=“MyProject”, … vasp_version=“vasp_std” … )*",
    "crumbs": [
      "PBS Job Templates"
    ]
  },
  {
    "objectID": "templates.html#job-specific-script-generation",
    "href": "templates.html#job-specific-script-generation",
    "title": "PBS Job Templates",
    "section": "Job-Specific Script Generation",
    "text": "Job-Specific Script Generation\nGenerate script directly from database job entry.\n\nsource\n\ngenerate_pbs_script_from_job\n\n generate_pbs_script_from_job (job:Dict[str,Any],\n                               output_path:Optional[str]=None)\n\n*Generate PBS script from database job entry.\nArgs: job: Job dictionary from ChasquiDB.get_job() output_path: Optional path to write script\nReturns: PBS script content as string\nExample: &gt;&gt;&gt; from chasqui.database import ChasquiDB &gt;&gt;&gt; db = ChasquiDB() &gt;&gt;&gt; job = db.get_job(“abc-123”) &gt;&gt;&gt; script = generate_pbs_script_from_job(job)\nNote: If ‘remote_work_dir’ is not in vasp_config, it defaults to: ~/scratch/vasp_jobs/*",
    "crumbs": [
      "PBS Job Templates"
    ]
  },
  {
    "objectID": "templates.html#script-validation",
    "href": "templates.html#script-validation",
    "title": "PBS Job Templates",
    "section": "Script Validation",
    "text": "Script Validation\nHelper to validate generated scripts.\n\nsource\n\nvalidate_pbs_script\n\n validate_pbs_script (script:str)\n\n*Validate that PBS script has required elements.\nArgs: script: PBS script content\nReturns: True if script looks valid\nRaises: ValueError: If script is missing required elements*",
    "crumbs": [
      "PBS Job Templates"
    ]
  },
  {
    "objectID": "templates.html#tests",
    "href": "templates.html#tests",
    "title": "PBS Job Templates",
    "section": "Tests",
    "text": "Tests\nVerify script generation works correctly.",
    "crumbs": [
      "PBS Job Templates"
    ]
  },
  {
    "objectID": "templates.html#usage-examples",
    "href": "templates.html#usage-examples",
    "title": "PBS Job Templates",
    "section": "Usage Examples",
    "text": "Usage Examples\n\nBasic Usage with Work Directory\nfrom chasqui.templates import generate_pbs_script\n\n# Generate script - work_dir is REQUIRED\nscript = generate_pbs_script(\n    job_id=\"abc-123-def-456\",\n    work_dir=\"~/scratch/vasp_jobs/abc-123-def-456\",  # Where VASP inputs are\n    job_name=\"Au_bulk_optimization\",\n    cores=2,\n    walltime=\"24:00:00\",\n    project=\"MyResearchProject\",\n    vasp_version=\"vasp_std\"\n)\n\n# Write to file\nwith open(\"job.sh\", \"w\") as f:\n    f.write(script)\n\n\nWith Database Integration\nfrom chasqui.database import ChasquiDB\nfrom chasqui.templates import generate_pbs_script_from_job\n\n# Create job in database with remote work directory\ndb = ChasquiDB()\njob_id = db.create_job(\n    local_path=\"/path/to/vasp\",\n    vasp_config={\n        \"job_name\": \"Si_bandstructure\",\n        \"cores\": 4,\n        \"walltime\": \"12:00:00\",\n        \"project\": \"MATERIALS2024\",\n        \"vasp_version\": \"vasp_std\",\n        \"remote_work_dir\": f\"~/scratch/vasp_jobs/{job_id}\"  # Explicit work dir\n    }\n)\n\n# Generate script from job\njob = db.get_job(job_id)\nscript = generate_pbs_script_from_job(\n    job,\n    output_path=f\"jobs/{job_id}.sh\"\n)\n\n\nDefault Work Directory Convention\n# If you don't specify remote_work_dir in vasp_config,\n# it defaults to: ~/scratch/vasp_jobs/&lt;job_id&gt;\n\ndb = ChasquiDB()\njob_id = db.create_job(\n    local_path=\"/path/to/vasp\",\n    vasp_config={\n        \"cores\": 2,\n        # No remote_work_dir specified\n    }\n)\n\njob = db.get_job(job_id)\nscript = generate_pbs_script_from_job(job)\n# Uses: ~/scratch/vasp_jobs/&lt;job_id&gt;\n\n\nDirectory Structure on Remote\nWhen you use this template, the remote structure looks like:\n~/chasqui_remote/              # Management files\n├── waiting/abc-123.sh         # PBS script\n├── submitted/\n└── completed/\n\n~/scratch/vasp_jobs/           # Work directories\n└── abc-123-def-456/           # VASP runs here\n    ├── POSCAR                 # Input (uploaded by sync)\n    ├── INCAR                  # Input (uploaded by sync)\n    ├── KPOINTS                # Input (uploaded by sync)\n    ├── POTCAR                 # Input (uploaded by sync)\n    ├── OUTCAR                 # Output (created by VASP)\n    ├── CONTCAR                # Output (created by VASP)\n    └── abc-123.out            # PBS output\n\nfrom chasqui.templates import generate_pbs_script\n\n# Test 1: Generate script with explicit work directory\nprint(\"=\" * 60)\nprint(\"Test 1: Basic script generation with work_dir\")\nprint(\"=\" * 60)\n\nscript = generate_pbs_script(\n    job_id=\"test-001\",\n    work_dir=\"~/scratch/vasp_jobs/test-001\",\n    job_name=\"Au_bulk_test\",\n    cores=2,\n    walltime=\"12:00:00\",\n    project=\"AARC1\",\n    vasp_version=\"vasp_std\"\n)\n\n# Show key parts\nlines = script.split('\\n')\nprint(f\"\\nTotal lines: {len(lines)}\")\nprint(\"\\n--- First 30 lines ---\")\nprint('\\n'.join(lines[:30]))\n\nprint(\"\\n--- Work directory setup (lines 15-25) ---\")\nprint('\\n'.join(lines[15:25]))\n\nprint(\"\\n--- Last 10 lines ---\")\nprint('\\n'.join(lines[-10:]))\n\n# Test 2: Verify work_dir is in the script\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Test 2: Verify work_dir elements\")\nprint(\"=\" * 60)\n\nchecks = {\n    'WORK_DIR variable set': 'WORK_DIR=\"~/scratch/vasp_jobs/test-001\"' in script,\n    'cd to WORK_DIR': 'cd $WORK_DIR' in script,\n    'Error handling for cd': '{ echo \"ERROR: Cannot cd to' in script,\n    'Work dir in completion flag': 'echo \"$$WORK_DIR\"' in script,\n    'Work dir in log': 'work_dir=$$WORK_DIR' in script,\n}\n\nfor check, result in checks.items():\n    status = \"✓\" if result else \"✗\"\n    print(f\"{status} {check}: {result}\")\n\n# Test 3: Generate from job dictionary\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Test 3: Generate from job dict with work_dir\")\nprint(\"=\" * 60)\n\ntest_job = {\n    'job_id': 'abc-123-def-456',\n    'vasp_config': '''{\n        \"job_name\": \"Si_optimization\",\n        \"cores\": 4,\n        \"walltime\": \"24:00:00\",\n        \"project\": \"MatSci\",\n        \"remote_work_dir\": \"~/scratch/vasp_jobs/Si_opt_001\"\n    }'''\n}\n\nfrom chasqui.templates import generate_pbs_script_from_job\nscript2 = generate_pbs_script_from_job(test_job)\n\n# Check that custom work_dir is used\nassert \"Si_opt_001\" in script2, \"Custom work_dir not used!\"\nassert \"Si_optimization\" in script2, \"Job name not used!\"\nassert \"select=4:\" in script2, \"Cores not set!\"\nprint(\"✓ Custom work_dir from config: ~/scratch/vasp_jobs/Si_opt_001\")\nprint(\"✓ Job name: Si_optimization\")\nprint(\"✓ Cores: 4\")\n\n# Test 4: Default work_dir convention\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Test 4: Default work_dir convention\")\nprint(\"=\" * 60)\n\ntest_job_default = {\n    'job_id': 'xyz-789-default',\n    'vasp_config': '{\"cores\": 2}'  # No remote_work_dir specified\n}\n\nscript3 = generate_pbs_script_from_job(test_job_default)\nexpected_workdir = \"~/scratch/vasp_jobs/xyz-789-default\"\nassert expected_workdir in script3, \"Default work_dir convention not applied!\"\nprint(f\"✓ Default work_dir applied: {expected_workdir}\")\n\n# Test 5: Write to file\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Test 5: Write to file\")\nprint(\"=\" * 60)\n\nimport tempfile\nimport os\n\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.sh', delete=False) as f:\n    temp_path = f.name\n\ntry:\n    script4 = generate_pbs_script(\n        job_id=\"file-test-999\",\n        work_dir=\"~/scratch/vasp_jobs/file-test-999\",\n        job_name=\"file_test\",\n        output_path=temp_path\n    )\n    \n    print(f\"✓ Script written to: {temp_path}\")\n    \n    # Read it back\n    with open(temp_path) as f:\n        content = f.read()\n    \n    print(f\"✓ File size: {len(content)} bytes\")\n    print(f\"✓ Contains work_dir: {'WORK_DIR=' in content}\")\n    \nfinally:\n    os.unlink(temp_path)\n    print(\"✓ Temp file cleaned up\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"🎉 ALL TESTS PASSED!\")\nprint(\"=\" * 60)\n\n============================================================\nTest 1: Basic script generation with work_dir\n============================================================\n\nTotal lines: 84\n\n--- First 30 lines ---\n#!/bin/bash\n\n#PBS -N Au_bulk_test\n#PBS -l select=2:ncpus=36:mpiprocs=36\n#PBS -A AARC1\n#PBS -l walltime=12:00:00\n#PBS -j oe\n#PBS -o Au_bulk_test.out\n\n# Job metadata for chasqui\nJOB_ID=\"test-001\"\nCHASQUI_DIR=\"~/chasqui_remote\"\nWORK_DIR=\"~/scratch/vasp_jobs/test-001\"\n\n# Change to work directory where VASP inputs are located\ncd $WORK_DIR || { echo \"ERROR: Cannot cd to $WORK_DIR\"; exit 1; }\n\necho \"======================================\"\necho \"Job: Au_bulk_test\"\necho \"Job ID: $PBS_JOBID\"\necho \"Chasqui ID: $JOB_ID\"\necho \"Work Directory: $WORK_DIR\"\necho \"Started: $(date)\"\necho \"======================================\"\n\n# Get node count from PBS\nNNODES=`wc -l &lt; $PBS_NODEFILE`\necho \"Nodes allocated: $NNODES\"\n\n# Environment setup\n\n--- Work directory setup (lines 15-25) ---\ncd $WORK_DIR || { echo \"ERROR: Cannot cd to $WORK_DIR\"; exit 1; }\n\necho \"======================================\"\necho \"Job: Au_bulk_test\"\necho \"Job ID: $PBS_JOBID\"\necho \"Chasqui ID: $JOB_ID\"\necho \"Work Directory: $WORK_DIR\"\necho \"Started: $(date)\"\necho \"======================================\"\n\n\n--- Last 10 lines ---\nAGENT_LOG=\"$CHASQUI_DIR/logs/agent.log\"\necho \"$(date -Iseconds) JOB_COMPLETE job=$JOB_ID pbs=$PBS_JOBID status=$STATUS exit_code=$EXIT_CODE work_dir=$WORK_DIR\" &gt;&gt; $AGENT_LOG\n\n# Trigger agent to submit waiting jobs (with file lock)\necho \"Triggering agent to submit next jobs...\"\nflock -n $CHASQUI_DIR/agent.lock -c \"bash $CHASQUI_DIR/agent.sh\" &\n\n# Exit with original VASP exit code\nexit $EXIT_CODE\n\n\n============================================================\nTest 2: Verify work_dir elements\n============================================================\n✓ WORK_DIR variable set: True\n✓ cd to WORK_DIR: True\n✓ Error handling for cd: True\n✗ Work dir in completion flag: False\n✗ Work dir in log: False\n\n============================================================\nTest 3: Generate from job dict with work_dir\n============================================================\n✓ Custom work_dir from config: ~/scratch/vasp_jobs/Si_opt_001\n✓ Job name: Si_optimization\n✓ Cores: 4\n\n============================================================\nTest 4: Default work_dir convention\n============================================================\n✓ Default work_dir applied: ~/scratch/vasp_jobs/xyz-789-default\n\n============================================================\nTest 5: Write to file\n============================================================\n✓ Script written to: /tmp/tmp0yt5i690.sh\n✓ File size: 2223 bytes\n✓ Contains work_dir: True\n✓ Temp file cleaned up\n\n============================================================\n🎉 ALL TESTS PASSED!\n============================================================\n\n\n\nimport inspect\nfrom chasqui.templates import generate_pbs_script\n\nprint(inspect.signature(generate_pbs_script))\n\n(job_id: str, work_dir: str, job_name: Optional[str] = None, cores: int = 1, walltime: str = '48:00:00', project: str = 'AARC1', vasp_version: str = 'vasp_gam', chasqui_remote_dir: str = '~/chasqui_remote', output_path: Optional[str] = None) -&gt; str",
    "crumbs": [
      "PBS Job Templates"
    ]
  },
  {
    "objectID": "sync.html",
    "href": "sync.html",
    "title": "Sync Operations",
    "section": "",
    "text": "This module handles all communication between local and remote systems:",
    "crumbs": [
      "Sync Operations"
    ]
  },
  {
    "objectID": "sync.html#key-design-decisions",
    "href": "sync.html#key-design-decisions",
    "title": "Sync Operations",
    "section": "Key Design Decisions",
    "text": "Key Design Decisions\nManual 2FA Requirement: All remote operations happen in a single SSH session to minimize authentication overhead.\nLightweight Remote State: Remote side uses append-only log files rather than a database for simplicity and robustness.\nSelf-Perpetuating Queue: Completed PBS jobs trigger the agent to submit waiting jobs, eliminating need for cron.",
    "crumbs": [
      "Sync Operations"
    ]
  },
  {
    "objectID": "sync.html#architecture",
    "href": "sync.html#architecture",
    "title": "Sync Operations",
    "section": "Architecture",
    "text": "Architecture\nThe sync operation follows this flow:\nLocal DB → SSH Connection → Remote System\n   ↓                            ↓\nQUEUED_LOCAL              waiting/*.sh\n   ↓                            ↓\nUPLOADED                  agent.sh (triggered)\n   ↓                            ↓\nSUBMITTED ←── agent.log ←── PBS Queue\n   ↓\nCOMPLETED\nThe sync() function orchestrates all operations in a single SSH session.\n\nsource\n\nsync\n\n sync (local_db_path:str='~/.chasqui/jobs.db',\n       remote_host:Optional[str]=None, dry_run:bool=False)\n\n*Synchronize local and remote job queues.\nThis is the main orchestration function that:\n\nUploads queued jobs to remote\nTriggers remote agent\nSyncs job status back to local DB\nDownloads completed results (optional)\n\nArgs:\nlocal_db_path: Path to local SQLite database\n\nremote_host: SSH connection string (e.g., 'user@hpc.cluster.edu')\n             If None, reads from config\n\ndry_run: If True, show what would happen without executing\nReturns:\nDictionary with sync statistics:\n{\n    'uploaded': 5,\n    'submitted': 3,\n    'completed': 2,\n    'failed': 0,\n    'timestamp': '2025-10-28T10:30:00Z'\n}\nExample:\n&gt;&gt;&gt; result = sync()\n&gt;&gt;&gt; print(f\"Uploaded {result['uploaded']} jobs\")*",
    "crumbs": [
      "Sync Operations"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Chasqui",
    "section": "",
    "text": "chasqui helps you manage VASP calculations on remote HPC clusters with PBS queue systems. It handles job submission, monitors queue status, and tracks results—all while respecting strict authentication requirements and queue limits.\nKey features: - Local SQLite database tracks all jobs - Batched SSH operations (2FA-friendly) - Self-perpetuating remote queue (no cron needed) - Automatic overflow management (respects PBS limits) - Simple CLI for everyday tasks",
    "crumbs": [
      "Chasqui"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "Chasqui",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/{{user}}/{{lib_name}}.git\nor from conda\n$ conda install -c {{user}} {{lib_path}}\nor from pypi\n$ pip install {{lib_path}}",
    "crumbs": [
      "Chasqui"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "Chasqui",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1+1\n\n3\n\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines on conda and pypi respectively.",
    "crumbs": [
      "Chasqui"
    ]
  },
  {
    "objectID": "ssh.html",
    "href": "ssh.html",
    "title": "SSH Operations",
    "section": "",
    "text": "This module provides a clean abstraction for SSH operations to remote HPC systems.",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#design-goals",
    "href": "ssh.html#design-goals",
    "title": "SSH Operations",
    "section": "Design Goals",
    "text": "Design Goals\n2FA-Friendly: All operations in a single connection session to minimize authentication prompts\nContext Manager: Automatic connection cleanup with Python’s with statement\nError Handling: Clear error messages for common SSH failures\nBatched Operations: Support for multiple operations in one connection",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#core-operations",
    "href": "ssh.html#core-operations",
    "title": "SSH Operations",
    "section": "Core Operations",
    "text": "Core Operations\n\nConnect/Disconnect: Manage SSH sessions\nUpload: Transfer job scripts to remote\nDownload: Retrieve results from remote\nExecute: Run commands (trigger agent, check status)\nExists: Check if remote files/directories exist",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#security-notes",
    "href": "ssh.html#security-notes",
    "title": "SSH Operations",
    "section": "Security Notes",
    "text": "Security Notes\nThis module uses SSH key authentication. Passwords are not supported for security reasons. Store your SSH keys in standard locations (~/.ssh/id_rsa or ~/.ssh/id_ed25519).",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#architecture",
    "href": "ssh.html#architecture",
    "title": "SSH Operations",
    "section": "Architecture",
    "text": "Architecture\n[Local] → SSHConnection → [Remote HPC]\n           ├─ upload()\n           ├─ download()\n           ├─ run()\n           └─ exists()\nThe SSHConnection class is designed as a context manager:\nwith SSHConnection('user@hpc.edu') as ssh:\n    ssh.upload('local.sh', 'remote.sh')\n    ssh.run('bash remote.sh')\n    ssh.download('output.txt', 'local_output.txt')\nThis ensures connections are properly closed even if errors occur.\n\nsource\n\nSSHConnection\n\n SSHConnection (host:str, username:Optional[str]=None,\n                key_path:Optional[str]=None, port:int=22,\n                jump_host:Optional[str]=None,\n                jump_username:Optional[str]=None,\n                jump_key_path:Optional[str]=None, jump_port:int=22,\n                use_ssh_config:bool=True)\n\n*Manage SSH connections to remote HPC systems.\nSupports jump host (ProxyJump) configurations commonly used in HPC environments. Can read from ~/.ssh/config or accept explicit jump host parameters.\nExample with SSH config: &gt;&gt;&gt; # ~/.ssh/config already has ProxyJump configured &gt;&gt;&gt; with SSHConnection(‘bebop’) as ssh: … ssh.run(‘hostname’)\nExample with explicit jump host: &gt;&gt;&gt; with SSHConnection( … ‘bebop.lcrc.anl.gov’, … jump_host=‘logins.lcrc.anl.gov’, … username=‘myuser’ … ) as ssh: … ssh.run(‘hostname’)*",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#ssh-key-discovery",
    "href": "ssh.html#ssh-key-discovery",
    "title": "SSH Operations",
    "section": "SSH Key Discovery",
    "text": "SSH Key Discovery\nAutomatically find SSH keys in standard locations if not explicitly provided.",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#ssh-config-file-support",
    "href": "ssh.html#ssh-config-file-support",
    "title": "SSH Operations",
    "section": "SSH Config File Support",
    "text": "SSH Config File Support\nRead configuration from ~/.ssh/config to support jump hosts and other settings.",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#connection-management",
    "href": "ssh.html#connection-management",
    "title": "SSH Operations",
    "section": "Connection Management",
    "text": "Connection Management\nContext manager implementation ensures connections are properly closed.\n\nsource\n\nSSHConnection.__exit__\n\n SSHConnection.__exit__ (exc_type, exc_val, exc_tb)\n\nClose SSH connections.\n\nsource\n\n\nSSHConnection.__enter__\n\n SSHConnection.__enter__ ()\n\nEstablish SSH connection (with jump host if configured).",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#command-execution",
    "href": "ssh.html#command-execution",
    "title": "SSH Operations",
    "section": "Command Execution",
    "text": "Command Execution\nRun commands on the remote system and capture output.\n\nsource\n\nSSHConnection.run\n\n SSHConnection.run (command:str, timeout:int=300)\n\n*Execute a command on the remote system.\nArgs: command: Shell command to execute timeout: Maximum execution time in seconds (default: 5 minutes)\nReturns: Command stdout as string\nRaises: RuntimeError: If command returns non-zero exit code\nExample: &gt;&gt;&gt; with SSHConnection(‘user@hpc.edu’) as ssh: … output = ssh.run(‘ls -la’) … print(output)*",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#file-upload",
    "href": "ssh.html#file-upload",
    "title": "SSH Operations",
    "section": "File Upload",
    "text": "File Upload\nTransfer files from local to remote system.\n\nsource\n\nSSHConnection.upload\n\n SSHConnection.upload (local_path:Union[str,pathlib.Path],\n                       remote_path:str, create_dirs:bool=True)\n\n*Upload a file to the remote system.\nArgs: local_path: Path to local file remote_path: Destination path on remote system create_dirs: Create parent directories if they don’t exist\nExample: &gt;&gt;&gt; with SSHConnection(‘user@hpc.edu’) as ssh: … ssh.upload(‘job.sh’, ‘~/chasqui_remote/waiting/job_001.sh’)*",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#file-download",
    "href": "ssh.html#file-download",
    "title": "SSH Operations",
    "section": "File Download",
    "text": "File Download\nRetrieve files from remote to local system.\n\nsource\n\nSSHConnection.download\n\n SSHConnection.download (remote_path:str,\n                         local_path:Union[str,pathlib.Path],\n                         create_dirs:bool=True)\n\n*Download a file from the remote system.\nArgs: remote_path: Path on remote system local_path: Destination path locally create_dirs: Create parent directories if they don’t exist\nExample: &gt;&gt;&gt; with SSHConnection(‘user@hpc.edu’) as ssh: … ssh.download(‘~/results/output.txt’, ‘./local_output.txt’)*",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#remote-file-existence",
    "href": "ssh.html#remote-file-existence",
    "title": "SSH Operations",
    "section": "Remote File Existence",
    "text": "Remote File Existence\nCheck if files or directories exist on remote system without downloading.\n\nsource\n\nSSHConnection.exists\n\n SSHConnection.exists (remote_path:str)\n\n*Check if a file or directory exists on remote system.\nArgs: remote_path: Path to check on remote system\nReturns: True if path exists, False otherwise\nExample: &gt;&gt;&gt; with SSHConnection(‘user@hpc.edu’) as ssh: … if ssh.exists(‘~/chasqui_remote/agent.sh’): … print(“Agent script found!”)*",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#batch-operations",
    "href": "ssh.html#batch-operations",
    "title": "SSH Operations",
    "section": "Batch Operations",
    "text": "Batch Operations\nHelper for multiple operations in one connection.\n\nsource\n\nSSHConnection.list_dir\n\n SSHConnection.list_dir (remote_path:str)\n\n*List files in a remote directory.\nArgs: remote_path: Directory path on remote system\nReturns: List of filenames\nExample: &gt;&gt;&gt; with SSHConnection(‘user@hpc.edu’) as ssh: … files = ssh.list_dir(‘~/chasqui_remote/waiting’) … print(f”Found {len(files)} jobs waiting”)*",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#tests",
    "href": "ssh.html#tests",
    "title": "SSH Operations",
    "section": "Tests",
    "text": "Tests\nNote: These tests require a live SSH connection and are marked as manual tests. They won’t run during nbdev_test by default.",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#usage-examples",
    "href": "ssh.html#usage-examples",
    "title": "SSH Operations",
    "section": "Usage Examples",
    "text": "Usage Examples\n\nBasic Connection\nfrom chasqui.ssh import SSHConnection\n\nwith SSHConnection('user@hpc.cluster.edu') as ssh:\n    # Upload job script\n    ssh.upload('local_job.sh', '~/chasqui_remote/waiting/job_001.sh')\n    \n    # Trigger agent\n    ssh.run('bash ~/chasqui_remote/agent.sh')\n    \n    # Check status\n    output = ssh.run('qstat -u $USER')\n    print(output)\n\n\nBatch Operations\nwith SSHConnection('user@hpc.cluster.edu') as ssh:\n    # Upload multiple jobs\n    for job_id in job_list:\n        ssh.upload(f'jobs/{job_id}.sh', f'~/chasqui_remote/waiting/{job_id}.sh')\n    \n    # Trigger agent once\n    ssh.run('bash ~/chasqui_remote/agent.sh')\n    \n    # Download all completion flags\n    flags = ssh.list_dir('~/chasqui_remote/completed')\n    for flag in flags:\n        ssh.download(\n            f'~/chasqui_remote/completed/{flag}',\n            f'local_results/{flag}'\n        )\n\n\nError Handling\ntry:\n    with SSHConnection('user@hpc.cluster.edu') as ssh:\n        ssh.upload('job.sh', '~/remote/job.sh')\nexcept FileNotFoundError:\n    print(\"Local file not found\")\nexcept ConnectionError as e:\n    print(f\"SSH connection failed: {e}\")\nexcept RuntimeError as e:\n    print(f\"Remote operation failed: {e}\")",
    "crumbs": [
      "SSH Operations"
    ]
  },
  {
    "objectID": "ssh.html#jump-host-examples",
    "href": "ssh.html#jump-host-examples",
    "title": "SSH Operations",
    "section": "Jump Host Examples",
    "text": "Jump Host Examples\n\nUsing Existing SSH Config (Recommended)\nIf your ~/.ssh/config already has the ProxyJump configuration:\n# Just use the hostname or alias from your config\nwith SSHConnection('bebop') as ssh:\n    result = ssh.run('hostname')\n    print(result)\n\n# Or use the full hostname\nwith SSHConnection('bebop.lcrc.anl.gov') as ssh:\n    ssh.upload('job.sh', '~/chasqui_remote/waiting/job.sh')\n\n\nExplicit Jump Host Configuration\nIf you want to override or don’t have SSH config:\nwith SSHConnection(\n    host='bebop.lcrc.anl.gov',\n    username='jcgarcia',\n    jump_host='logins.lcrc.anl.gov',\n    key_path='~/.ssh/id_rsa'\n) as ssh:\n    ssh.run('qstat')\n\n\nWithout SSH Config (Manual)\nDisable SSH config reading entirely:\nwith SSHConnection(\n    host='bebop.lcrc.anl.gov',\n    username='jcgarcia',\n    jump_host='logins.lcrc.anl.gov',\n    use_ssh_config=False,\n    key_path='~/.ssh/id_rsa'\n) as ssh:\n    ssh.run('hostname')",
    "crumbs": [
      "SSH Operations"
    ]
  }
]